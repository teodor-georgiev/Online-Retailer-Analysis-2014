{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from category_encoders import LeaveOneOutEncoder,WOEEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette = \"Dark2\")\n",
    "my_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "  (0.8509803921568627, 0.37254901960784315, 0.00784313725490196)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "from itertools import chain, combinations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import tensorflow as tensorflow\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for all the models\n",
    "class Model:\n",
    "    def __init__(self, df:dict):\n",
    "        self.df = df\n",
    "        self.k = max(df[\"order_item_id\"])-1\n",
    "        \n",
    "    def split_data(self, historic:bool)->tuple:\n",
    "        \"\"\"\n",
    "        Split the data into train and test sets, depending on whether the encdoder needs to be fited on the full data or not.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        historic : bool\n",
    "            0 if the encoder needs to be fited on the Months April to February and to transform March\n",
    "            1 if the encoder needs to be fited on the Months April to December and to transform January to March\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            df_train : dict\n",
    "                Dataframe with training data.\n",
    "            df_test : dict\n",
    "                Dataframe with testing data.\n",
    "        \"\"\"\n",
    "        # Get list of the months to train, remove months on which to test        \n",
    "        if historic:\n",
    "            months_to_train = list(range(1,13))\n",
    "            months_to_train.remove(12,1,2,3)\n",
    "        else:\n",
    "            months_to_train = list(range(1,13))\n",
    "            months_to_train.remove(3)\n",
    "        # Split into train and test. \"~\" in front of a variable means \"not\"\n",
    "        df_train = self.df.loc[:k][self.df.loc[:k,\"order_month\"].isin(months_to_train)]\n",
    "        df_test = self.df.loc[:k][~self.df.loc[:k,\"order_month\"].isin(months_to_train)]\n",
    "        # Get the validation set\n",
    "        # df_valid = self.df.iloc[k+1:, :]\n",
    "        # Drop unnecessary columns\n",
    "        columns_to_drop = [\"order_date\", \"delivery_date\", \"user_dob\", \"user_reg_date\", \"order_id\",\"order_item_id\"]\n",
    "        df_train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        df_test.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        return df_train, df_test\n",
    "    \n",
    "    def LOE_Encoder(self, df_train:dict, df_test:dict, columns:list ,sig:float)->tuple:\n",
    "        \"\"\"\n",
    "        Leave One Out Encoder to calculate the response variable for each category.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_train : dict\n",
    "            Dataframe with training data.\n",
    "        df_test : dict\n",
    "            Dataframe with testing data.\n",
    "        columns : list\n",
    "            Categorical columns to encode.\n",
    "        sig : float\n",
    "            Random noise added to the response variable.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            _description_\n",
    "        \"\"\"              \n",
    "        encoder = LeaveOneOutEncoder(cols=columns, return_df=True,sigma=sig)\n",
    "        df_encode_train = encoder.fit_transform(df_train.drop([\"return\"],axis=1),df_train[[\"return\"]])\n",
    "        df_encode_test = encoder.transform(df_test.drop([\"return\"],axis=1))\n",
    "        df_encode_train , df_encode_test = df_encode_train.join(df_train[[\"return\"]]), df_encode_test.join(df_test[[\"return\"]])\n",
    "        return df_encode_train, df_encode_test, encoder\n",
    "    \n",
    "    def neural_network(self, df_train:dict, df_test:dict, n_layers:int, n_nodes:int, dropout:list, activation:str, optimizer:str, loss:str, metrics:list, epochs:int, batch_size:int,verbose:int)->object:\n",
    "        \"\"\"\n",
    "        Neural network model to predict whether an item will be returned or not.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_train : dict\n",
    "            Dataframe with training data.\n",
    "        df_test : dict\n",
    "            Dataframe with testing data.\n",
    "        n_layers : int\n",
    "            Number of layers in the neural network\n",
    "        n_nodes : int\n",
    "            Number of nodes in each layer\n",
    "        dropout : list\n",
    "            List of dropout rates for each layer\n",
    "        activation : str\n",
    "            Activation function for each layer except the last one\n",
    "        optimizer : str\n",
    "            Optimizer for the neural network\n",
    "        loss : str\n",
    "            Loss function for the neural network\n",
    "        metrics : str\n",
    "            List of metrics for the neural network\n",
    "        epochs : int\n",
    "            Number of epochs for the neural network\n",
    "        batch_size : int\n",
    "            Size of the batch\n",
    "        verbose : int\n",
    "            Whether to print the progress of the neural network\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model: object\n",
    "            The Neural network model\n",
    "        Y_pred: array\n",
    "            Array of floats with the predictions of the neural network\n",
    "        mae: float\n",
    "            Mean absolute error on the testing set\n",
    "        \"\"\"         \n",
    "        X_train, Y_train = df_train.drop([\"return\"],axis=1), df_train[\"return\"]\n",
    "        X_test, Y_test = df_test.drop([\"return\"],axis=1), df_test[\"return\"]\n",
    "        X_train = StandardScaler().fit_transform(X_train)\n",
    "        X_test = StandardScaler().fit_transform(X_test)\n",
    "        \n",
    "        model = Sequential()\n",
    "        for i in range(n_layers):\n",
    "            if i == 0:\n",
    "                model.add(Dense(n_nodes, input_dim=len(self.df.columns), activation=activation))\n",
    "            else:\n",
    "                model.add(Dense(n_nodes, activation=activation))\n",
    "            model.add(Dropout(dropout[i]))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        model.fit(self.df, epochs=epochs, batch_size=batch_size,verbose=verbose)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(Y_test, Y_pred)\n",
    "        return model, Y_pred, mae\n",
    "    \n",
    "    def xgboost(self, df_train:dict, df_test:dict, params:dict, verbose:int):\n",
    "        X_train, Y_train = df_train.drop([\"return\"],axis=1), df_train[\"return\"]\n",
    "        X_test, Y_test = df_test.drop([\"return\"],axis=1), df_test[\"return\"]\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, Y_train, verbose=verbose)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(Y_test, Y_pred)\n",
    "        return model, Y_pred, mae\n",
    "    \n",
    "    def catboost(self, df_train:dict, df_test:dict, params:dict, verbose:int):\n",
    "        X_train, Y_train = df_train.drop([\"return\"],axis=1), df_train[\"return\"]\n",
    "        X_test, Y_test = df_test.drop([\"return\"],axis=1), df_test[\"return\"]\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, Y_train, verbose=verbose)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(Y_test, Y_pred)\n",
    "        return model, Y_pred, mae\n",
    "    \n",
    "    def lightgmb(self, df_train:dict, df_test:dict, params:dict, verbose:int):\n",
    "        X_train, Y_train = df_train.drop([\"return\"],axis=1), df_train[\"return\"]\n",
    "        X_test, Y_test = df_test.drop([\"return\"],axis=1), df_test[\"return\"]\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_train, Y_train, verbose=verbose)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(Y_test, Y_pred)\n",
    "        return model, Y_pred, mae\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd16a1c2e981052eaae61151b9525ae9913f1f0d16bca6b7e7be9e0f29d739d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
